{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "imputation_column.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandeep0412/Data-Imputation-on-Psychology-Data/blob/master/imputation_column.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS-XETQEuPLt",
        "colab_type": "code",
        "outputId": "1c5e2347-a165-42b4-8dba-23953ce9af98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Be6r9BaiuTyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from prettytable import PrettyTable\n",
        "import random\n",
        "from math import floor\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMpxp-Mnu-Be",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Standardize numerical Values\n",
        "def standardize_col(col):\n",
        "    return (col - col.min()) * 1.0 / (col.max() - col.min())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI2vSB9pvF7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#order the columns of the dataframe according to decreasing number of null values, return list of column names\n",
        "def ordered_cols(df):\n",
        "  x = df.isna().sum()\n",
        "  x = x.sort_values()\n",
        "  x = x.to_frame()\n",
        "  columns_sorted = x.index.values\n",
        "  return list(columns_sorted)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERDvRCNkFQr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecisionTree(object):\n",
        "    \"\"\"\n",
        "    Class to create decision tree model (CART)\n",
        "    \"\"\"\n",
        "    def __init__(self, _max_depth, _min_splits):\n",
        "        self.max_depth = _max_depth\n",
        "        self.min_splits = _min_splits\n",
        "\n",
        "    def fit(self, _feature, _label):\n",
        "        \"\"\"\n",
        "        :param _feature:\n",
        "        :param _label:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        self.feature = _feature\n",
        "        self.label = _label\n",
        "        self.train_data = np.column_stack((self.feature,self.label))\n",
        "        self.build_tree()\n",
        "\n",
        "\n",
        "    def compute_gini_similarity(self, groups, class_labels):\n",
        "        \"\"\"\n",
        "        compute the gini index for the groups and class labels\n",
        "        :param groups:\n",
        "        :param class_labels:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        num_sample = sum([len(group) for group in groups])\n",
        "        gini_score = 0\n",
        "\n",
        "        for group in groups:\n",
        "            size = float(len(group))\n",
        "\n",
        "            if size == 0:\n",
        "                continue\n",
        "            score = 0.0\n",
        "            for label in class_labels:\n",
        "                porportion = (group[:,-1] == label).sum() / size\n",
        "                score += porportion * porportion\n",
        "            gini_score += (1.0 - score) * (size/num_sample)\n",
        "\n",
        "        return gini_score\n",
        "\n",
        "    def terminal_node(self, _group):\n",
        "        \"\"\"\n",
        "        Function set terminal node as the most common class in the group to make prediction later on\n",
        "        is an helper function used to mark the leaf node in the tree based on the early stop condition\n",
        "        or actual stop condition which ever is meet early\n",
        "        :param _group:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        class_labels, count = np.unique(_group[:,-1], return_counts= True)\n",
        "        return class_labels[np.argmax(count)]\n",
        "\n",
        "    def split(self, index, val, data):\n",
        "        \"\"\"\n",
        "        split features into two groups based on their values\n",
        "        :param index:\n",
        "        :param val:\n",
        "        :param data:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        data_left = np.array([]).reshape(0,self.train_data.shape[1])\n",
        "        data_right = np.array([]).reshape(0, self.train_data.shape[1])\n",
        "\n",
        "        for row in data:\n",
        "            if row[index] <= val :\n",
        "                data_left = np.vstack((data_left,row))\n",
        "\n",
        "            if row[index] > val:\n",
        "                data_right = np.vstack((data_right, row))\n",
        "\n",
        "        return data_left, data_right\n",
        "\n",
        "    def best_split(self, data):\n",
        "        \"\"\"\n",
        "        find the best split information using the gini score\n",
        "        :param data:\n",
        "        :return best_split result dict:\n",
        "        \"\"\"\n",
        "        class_labels = np.unique(data[:,-1])\n",
        "        best_index = 999\n",
        "        best_val = 999\n",
        "        best_score = 999\n",
        "        best_groups = None\n",
        "\n",
        "        for idx in range(data.shape[1]-1):\n",
        "            for row in data:\n",
        "                groups = self.split(idx, row[idx], data)\n",
        "                gini_score = self.compute_gini_similarity(groups,class_labels)\n",
        "\n",
        "                if gini_score < best_score:\n",
        "                    best_index = idx\n",
        "                    best_val = row[idx]\n",
        "                    best_score = gini_score\n",
        "                    best_groups = groups\n",
        "        result = {}\n",
        "        result['index'] = best_index\n",
        "        result['val'] = best_val\n",
        "        result['groups'] = best_groups\n",
        "        return result\n",
        "\n",
        "\n",
        "    def split_branch(self, node, depth):\n",
        "        \"\"\"\n",
        "        recursively split the data and\n",
        "        check for early stop argument based on self.max_depth and self.min_splits\n",
        "        - check if left or right groups are empty is yess craete terminal node\n",
        "        - check if we have reached max_depth early stop condition if yes create terminal node\n",
        "        - Consider left node, check if the group is too small using min_split condition\n",
        "            - if yes create terminal node\n",
        "            - else continue to build the tree\n",
        "        - same is done to the right side as well.\n",
        "        else\n",
        "        :param node:\n",
        "        :param depth:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        left_node , right_node = node['groups']\n",
        "        del(node['groups'])\n",
        "\n",
        "        if not isinstance(left_node,np.ndarray) or not isinstance(right_node,np.ndarray):\n",
        "            node['left'] = self.terminal_node(left_node + right_node)\n",
        "            node['right'] = self.terminal_node(left_node + right_node)\n",
        "            return\n",
        "\n",
        "        if depth >= self.max_depth:\n",
        "            node['left'] = self.terminal_node(left_node)\n",
        "            node['right'] = self.terminal_node(right_node)\n",
        "            return\n",
        "\n",
        "        if len(left_node) <= self.min_splits:\n",
        "            node['left'] = self.terminal_node(left_node)\n",
        "        else:\n",
        "            node['left'] = self.best_split(left_node)\n",
        "            self.split_branch(node['left'],depth + 1)\n",
        "\n",
        "\n",
        "        if len(right_node) <= self.min_splits:\n",
        "            node['right'] = self.terminal_node(right_node)\n",
        "        else:\n",
        "            node['right'] = self.best_split(right_node)\n",
        "            self.split_branch(node['right'],depth + 1)\n",
        "\n",
        "    def build_tree(self):\n",
        "        \"\"\"\n",
        "        build tree recursively with help of split_branch function\n",
        "         - Create a root node\n",
        "         - call recursive split_branch to build the complete tree\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        self.root = self.best_split(self.train_data)\n",
        "        self.split_branch(self.root, 1)\n",
        "        return self.root\n",
        "\n",
        "    def _predict(self, node, row):\n",
        "        \"\"\"\n",
        "        Recursively traverse through the tress to determine the\n",
        "        class of unseen sample data point during prediction\n",
        "        :param node:\n",
        "        :param row:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        if row[node['index']] < node['val']:\n",
        "            if isinstance(node['left'], dict):\n",
        "                return self._predict(node['left'], row)\n",
        "            else:\n",
        "                return node['left']\n",
        "\n",
        "        else:\n",
        "            if isinstance(node['right'],dict):\n",
        "                return self._predict(node['right'],row)\n",
        "            else:\n",
        "                return node['right']\n",
        "\n",
        "    def predict(self, test_data):\n",
        "        \"\"\"\n",
        "        predict the set of data point\n",
        "        :param test_data:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        self.predicted_label = np.array([])\n",
        "        for idx in test_data:\n",
        "            self.predicted_label = np.append(self.predicted_label, self._predict(self.root,idx))\n",
        "\n",
        "        return self.predicted_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX6Dc5BkO00W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def impute(df):\n",
        "  #initial imputed values\n",
        "  \n",
        "  Z = np.matrix(df['previous_session_id']).reshape(-1,1)\n",
        "  indexes_dict = {}\n",
        "  \n",
        "  #Get ordered list of col names except the session id which is always filled\n",
        "  col_partial = ordered_cols(df.loc[:, df.columns != 'previous_session_id'])\n",
        "  col_list = col_partial\n",
        "#   print(col_partial)\n",
        "  \n",
        "  \n",
        "  for col in col_partial:\n",
        "  #   print(col)\n",
        "    y  = df[col]\n",
        "  #   print(type(y))\n",
        "    pos = list(y[y.isnull()].index)\n",
        "  #   print(pos)\n",
        "    indexes_dict[col] = pos\n",
        "\n",
        "    X_train = np.delete(Z, pos, axis=0)\n",
        "    X_test = Z[pos, :]\n",
        "    y_train = np.matrix(y.drop(y.index[pos])).reshape(Z.shape[0]-len(pos),1)\n",
        "\n",
        "    y_final = np.matrix(y).reshape(Z.shape[0],1)\n",
        "\n",
        "  #   print(y.values.reshape(Z.shape[0],1)[pos[0]])\n",
        "  #   X_test = Z.loc[pos].values#.reshape(1,-1)\n",
        "  #   y_train = (y.drop(y.index[pos])).values(columns = 1)\n",
        "  #   X_train = (Z.drop(Z.index[pos])).values\n",
        "  #   X_train = (X_train).values#.reshape(-1,1)\n",
        "\n",
        "    clf = tree.DecisionTreeRegressor()\n",
        "    clf = clf.fit(X_train, y_train)\n",
        "\n",
        "    predicted = clf.predict(X_test)\n",
        "  #   print(predicted)\n",
        "\n",
        "    for i in range(len(pos)):\n",
        "      ind = pos[i]\n",
        "      y_final[ind] = predicted[i]\n",
        "\n",
        "    Z = np.concatenate((Z,y_final),axis = 1)\n",
        "  #   break\n",
        "  \n",
        "  #Converge 10 times\n",
        "  for l in range(10):\n",
        "    for colm in range(1,Z.shape[1]):\n",
        "      column_name = col_partial[colm-1]\n",
        "      pos = indexes_dict[column_name]\n",
        "\n",
        "      X_train = np.delete(Z, colm, axis=1)\n",
        "      X_train = np.delete(X_train, pos, axis=0)\n",
        "      X_test = np.delete(Z[pos, :], colm, axis=1)\n",
        "      y_train = Z[:, colm]\n",
        "      y_train = np.delete(y_train, pos, axis=0)\n",
        "\n",
        "  #     print(X_train.shape)\n",
        "  #     print(X_test.shape)\n",
        "  #     print(y_train.shape)\n",
        "\n",
        "      clf = tree.DecisionTreeRegressor()\n",
        "      clf = clf.fit(X_train, y_train)\n",
        "\n",
        "      predicted = clf.predict(X_test)\n",
        "\n",
        "      for i in range(len(pos)):\n",
        "        ind = pos[i]\n",
        "        Z[ind, colm] = predicted[i]\n",
        "  \n",
        "  col_list = ['previous_session_id'] + col_list\n",
        "#   print(col_list)\n",
        "  return pd.DataFrame(Z, columns=col_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5wKMJMew5NZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_col(df):\n",
        "  col_cnt = 50\n",
        "  for col in df.columns:\n",
        "    if col != 'previous_session_id' :\n",
        "      print(col)\n",
        "    #   print(data_num_ordered[col].notnull())\n",
        "      obs_ind = list(np.where(df[col].notnull())[0])\n",
        "#       print(len(obs_ind))\n",
        "\n",
        "      x_values = []\n",
        "      y_values = []\n",
        "\n",
        "      data_copy = df\n",
        "#       print(df)\n",
        "      for i in range(floor(0.05*len(obs_ind))):\n",
        "        leave_ind = (random.choice(obs_ind))\n",
        "        x_values.append(data_copy[col][leave_ind])\n",
        "        data_copy[col][leave_ind] = np.nan\n",
        "\n",
        "        imputed = impute(df)\n",
        "#         print(type(imputed))\n",
        "        y_values.append(imputed[col][leave_ind])\n",
        "\n",
        "#         print(y_values)\n",
        "      rmse = mean_squared_error(x_values,y_values)\n",
        "      print(\"col: \"+ str(col) + \"rmse: \"+ str(rmse) )\n",
        "      plt.figure()\n",
        "      plt.plot(x_values, x_values, 'r--', x_values, y_values, 'bo')\n",
        "      plt.xlabel('observed value')  \n",
        "      plt.ylabel('imputed value') \n",
        "      plt.title(col)\n",
        "      plt.show()\n",
        "      \n",
        "      col_cnt -=1\n",
        "      if col_cnt==0:\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5Tel9Jsc8sR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls 'drive/My Drive'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJkh417Zx89x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_num=pd.read_csv(\"/content/drive/My Drive/data_num.csv\",encoding='unicode_escape')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGOtTddxcX2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "for col in data_num.columns:\n",
        "    data_num[col] = standardize_col(data_num[col])\n",
        "    \n",
        "plot_col(data_num)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}